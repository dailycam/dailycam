"""Gemini AI Tools for content curation"""

import os
import requests
from typing import List, Dict, Any, Optional
from googleapiclient.discovery import build
from tavily import TavilyClient
from duckduckgo_search import DDGS
from bs4 import BeautifulSoup


class YouTubeSearchTool:
    """YouTube ì˜ìƒ ê²€ìƒ‰ ë„êµ¬"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("YOUTUBE_API_KEY")
        if self.api_key:
            self.youtube = build('youtube', 'v3', developerKey=self.api_key)
        else:
            self.youtube = None
            print("âš ï¸ [YouTubeSearchTool] YOUTUBE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. DuckDuckGo ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def search_videos(
        self, 
        query: str, 
        max_results: int = 10,
        min_views: int = 10000
    ) -> List[Dict[str, Any]]:
        """
        YouTube ì˜ìƒ ê²€ìƒ‰
        """
        if self.youtube:
            return self._search_with_api(query, max_results, min_views)
        else:
            return self._search_with_ddg(query, max_results)
            
    def _search_with_api(self, query: str, max_results: int, min_views: int) -> List[Dict[str, Any]]:
        try:
            # ì˜ìƒ ê²€ìƒ‰
            search_response = self.youtube.search().list(
                part="snippet",
                q=query,
                type="video",
                maxResults=max_results,  # 2ë°°ìˆ˜ ì œê±°í•˜ì—¬ Quota ì ˆì•½
                relevanceLanguage="ko",
                order="relevance",
                regionCode="KR"
            ).execute()
            
            videos = []
            for item in search_response.get('items', []):
                video_id = item['id']['videoId']
                snippet = item['snippet']
                
                # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì¡°íšŒìˆ˜ í™•ì¸)
                # Quota ì ˆì•½ì„ ìœ„í•´ ìƒì„¸ ì •ë³´ ì¡°íšŒëŠ” ìµœì†Œí™”í•˜ê±°ë‚˜ ìƒëµ ê³ ë ¤ ê°€ëŠ¥
                # ì—¬ê¸°ì„œëŠ” ìœ ì§€í•˜ë˜ ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”
                try:
                    video_response = self.youtube.videos().list(
                        part="statistics,contentDetails",
                        id=video_id
                    ).execute()
                    
                    if video_response['items']:
                        stats = video_response['items'][0]['statistics']
                        view_count = int(stats.get('viewCount', 0))
                        
                        if view_count >= min_views:
                            videos.append({
                                'video_id': video_id,
                                'title': snippet['title'],
                                'description': snippet['description'],
                                'channel': snippet['channelTitle'],
                                'thumbnail': snippet['thumbnails']['high']['url'],
                                'published_at': snippet['publishedAt'],
                                'view_count': view_count,
                                'url': f"https://www.youtube.com/watch?v={video_id}"
                            })
                except Exception:
                    # ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´ë§Œìœ¼ë¡œ ì¶”ê°€ (Quota ì ˆì•½)
                    videos.append({
                        'video_id': video_id,
                        'title': snippet['title'],
                        'description': snippet['description'],
                        'channel': snippet['channelTitle'],
                        'thumbnail': snippet['thumbnails']['high']['url'],
                        'published_at': snippet['publishedAt'],
                        'view_count': 0,
                        'url': f"https://www.youtube.com/watch?v={video_id}"
                    })
                
                if len(videos) >= max_results:
                    break
            
            return videos[:max_results]
            
        except Exception as e:
            print(f"YouTube API ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            # API ì˜¤ë¥˜ ì‹œ DuckDuckGoë¡œ Fallback
            print("âš ï¸ [YouTube] API ì˜¤ë¥˜ ë°œìƒ. DuckDuckGo ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            return self._search_with_ddg(query, max_results)

    def _search_with_ddg(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """DuckDuckGoë¥¼ ì‚¬ìš©í•œ YouTube ê²€ìƒ‰ (API í‚¤ ì—†ì„ ë•Œ)"""
        try:
            with DDGS() as ddgs:
                results = ddgs.videos(
                    keywords=f"{query} site:youtube.com",
                    region="kr-kr",
                    safesearch="moderate",
                    max_results=max_results * 2
                )
                
                videos = []
                for r in results:
                    # DDG ê²°ê³¼ ë§¤í•‘
                    # r = {'content': '...', 'description': '...', 'duration': '...', 'embed_html': '...', 'embed_url': '...', 'images': {...}, 'provider': 'YouTube', 'published': '...', 'publisher': '...', 'statistics': {'viewCount': ...}, 'title': '...', 'uploader': '...', 'url': '...'}
                    
                    # ì¡°íšŒìˆ˜ í™•ì¸ (DDG ê²°ê³¼ì— statisticsê°€ ìˆëŠ” ê²½ìš°)
                    view_count = 0
                    if 'statistics' in r and 'viewCount' in r['statistics']:
                        view_count = r['statistics']['viewCount']
                    elif 'views' in r: # ì¼ë¶€ ë²„ì „ì—ì„œëŠ” viewsë¡œ ì˜´
                        view_count = r['views']
                        
                    videos.append({
                        'video_id': r.get('id', ''), # DDGëŠ” IDë¥¼ ì§ì ‘ ì£¼ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                        'title': r.get('title', ''),
                        'description': r.get('description', ''),
                        'channel': r.get('uploader', ''),
                        'thumbnail': r.get('images', {}).get('large', '') or r.get('image', ''),
                        'published_at': r.get('published', ''),
                        'view_count': view_count,
                        'url': r.get('content', '') or r.get('url', '')
                    })
                    
                    if len(videos) >= max_results:
                        break
                        
                return videos
        except Exception as e:
            print(f"DuckDuckGo ì˜ìƒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []


class WebSearchTool:
    """ì›¹ ê²€ìƒ‰ ë„êµ¬ (Tavily or DuckDuckGo)"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("TAVILY_API_KEY")
        if self.api_key:
            self.client = TavilyClient(api_key=self.api_key)
        else:
            self.client = None
            print("âš ï¸ [WebSearchTool] TAVILY_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. DuckDuckGo ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def search_blogs(
        self, 
        query: str, 
        max_results: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ìœ¡ì•„ ë¸”ë¡œê·¸ ê²€ìƒ‰
        """
        if self.client:
            return self._search_with_tavily(query, max_results)
        else:
            return self._search_with_ddg(query, max_results)

    def _search_with_tavily(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        try:
            response = self.client.search(
                query=query + " ìœ¡ì•„ ë¸”ë¡œê·¸",
                search_depth="advanced",
                max_results=max_results,
                include_domains=[
                    "blog.naver.com",
                    "brunch.co.kr",
                    "tistory.com",
                    "velog.io"
                ]
            )
            
            blogs = []
            for result in response.get('results', []):
                blogs.append({
                    'title': result.get('title', ''),
                    'description': result.get('content', '')[:200],
                    'url': result.get('url', ''),
                    'score': result.get('score', 0.0)
                })
            
            return blogs
            
        except Exception as e:
            print(f"Tavily ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _search_with_ddg(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """DuckDuckGoë¥¼ ì‚¬ìš©í•œ ë¸”ë¡œê·¸ ê²€ìƒ‰ (API í‚¤ ì—†ì„ ë•Œ)"""
        try:
            with DDGS() as ddgs:
                # í•œêµ­ ë¸”ë¡œê·¸ ìœ„ì£¼ë¡œ ê²€ìƒ‰
                search_query = f"{query} (site:blog.naver.com OR site:brunch.co.kr OR site:tistory.com)"
                results = ddgs.text(
                    keywords=search_query,
                    region="kr-kr",
                    safesearch="moderate",
                    max_results=max_results
                )
                
                blogs = []
                import json
                import re
                
                for r in results:
                    # description ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    desc = r.get('body', '')
                    if not isinstance(desc, str):
                        desc = str(desc) if desc else ''
                    
                    # DuckDuckGo JSON ì•„í‹°íŒ©íŠ¸ ì²˜ë¦¬
                    if desc.strip().startswith('{"title":'):
                        # 1. JSON íŒŒì‹± ì‹œë„
                        try:
                            parsed = json.loads(desc)
                            desc = parsed.get('snippet', parsed.get('body', ''))
                        except:
                            # 2. íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ìœ¼ë¡œ snippet ì¶”ì¶œ ì‹œë„
                            match = re.search(r'"snippet":"(.*?)(?:"[,}]|$)', desc)
                            if match:
                                desc = match.group(1).replace('\\"', '"').replace('\\n', ' ')
                            else:
                                # 3. ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ JSON ë©ì–´ë¦¬ë¥¼ ë³´ì—¬ì£¼ëŠë‹ˆ ì°¨ë¼ë¦¬ ë¹ˆì¹¸ìœ¼ë¡œ ì²˜ë¦¬
                                desc = ''
                    
                    # HTML íƒœê·¸ ë° ë‚¨ì€ íŠ¹ìˆ˜ë¬¸ì ì œê±°
                    desc = re.sub(r'<[^>]+>', '', desc)
                    desc = desc.replace('{"title":', '').replace('"source":', '')
                    
                    blogs.append({
                        'title': r.get('title', ''),
                        'description': desc.strip()[:200],
                        'url': r.get('href', ''),
                        'score': 0.0
                    })
                    
                return blogs
        except Exception as e:
            print(f"DuckDuckGo ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []


def extract_blog_thumbnail(url: str) -> Optional[str]:
    """ë¸”ë¡œê·¸ URLì—ì„œ Open Graph ì¸ë„¤ì¼ ì¶”ì¶œ"""
    try:
        print(f"ğŸ–¼ï¸ [Thumbnail] ì¶”ì¶œ ì‹œë„: {url}")
        
        # User-Agent ì„¤ì • (ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì ‘ê·¼ ì‹œ í•„ìš”)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Open Graph ì´ë¯¸ì§€ ì°¾ê¸°
        og_image = soup.find('meta', property='og:image')
        if og_image and og_image.get('content'):
            thumbnail_url = og_image['content']
            print(f"âœ… [Thumbnail] OG ì´ë¯¸ì§€ ë°œê²¬: {thumbnail_url[:80]}...")
            return thumbnail_url
        
        # Twitter ì¹´ë“œ ì´ë¯¸ì§€ ì°¾ê¸° (ëŒ€ì²´)
        twitter_image = soup.find('meta', attrs={'name': 'twitter:image'})
        if twitter_image and twitter_image.get('content'):
            thumbnail_url = twitter_image['content']
            print(f"âœ… [Thumbnail] Twitter ì´ë¯¸ì§€ ë°œê²¬: {thumbnail_url[:80]}...")
            return thumbnail_url
        
        # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì°¾ê¸° (ìµœí›„ì˜ ìˆ˜ë‹¨)
        first_img = soup.find('img')
        if first_img and first_img.get('src'):
            img_src = first_img['src']
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            if img_src.startswith('//'):
                thumbnail_url = 'https:' + img_src
                print(f"âœ… [Thumbnail] ì²« ì´ë¯¸ì§€ ë°œê²¬ (//): {thumbnail_url[:80]}...")
                return thumbnail_url
            elif img_src.startswith('/'):
                from urllib.parse import urlparse
                parsed = urlparse(url)
                thumbnail_url = f"{parsed.scheme}://{parsed.netloc}{img_src}"
                print(f"âœ… [Thumbnail] ì²« ì´ë¯¸ì§€ ë°œê²¬ (/): {thumbnail_url[:80]}...")
                return thumbnail_url
            print(f"âœ… [Thumbnail] ì²« ì´ë¯¸ì§€ ë°œê²¬: {img_src[:80]}...")
            return img_src
        
        print(f"âš ï¸ [Thumbnail] ì´ë¯¸ì§€ ì—†ìŒ: {url}")
        return None
    except Exception as e:
        print(f"âŒ [Thumbnail] ì¶”ì¶œ ì˜¤ë¥˜ ({url}): {e}")
        return None

